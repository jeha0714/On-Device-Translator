import streamlit as st
import speech_recognition as sr
from faster_whisper import WhisperModel
import argostranslate.translate
import os
import time
import queue
import threading
import io

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="On-Device Translator", page_icon="ğŸ“œ", layout="wide")
st.title("ğŸ“œ Scrollable Real-time Translator")

# 2. ìŠ¤íƒ€ì¼ ì •ì˜ (ìŠ¤í¬ë¡¤ ê¸°ëŠ¥ ì¶”ê°€ë¨)
st.markdown("""
<style>
    .main-container { display: flex; flex-direction: row; gap: 20px; }
    
    /* [í•µì‹¬ ìˆ˜ì •] ë°•ìŠ¤ ìŠ¤íƒ€ì¼ ë³€ê²½ */
    .box { 
        padding: 20px; 
        border-radius: 10px; 
        
        /* ë†’ì´ë¥¼ ê³ ì •í•˜ê³  ìŠ¤í¬ë¡¤ì„ ë§Œë“­ë‹ˆë‹¤ */
        height: 60vh;          /* í™”ë©´ ë†’ì´ì˜ 60% ì°¨ì§€ */
        overflow-y: auto;      /* ì„¸ë¡œ ìŠ¤í¬ë¡¤ ìë™ ìƒì„± */
        
        font-size: 18px;       /* ê°€ë…ì„±ì„ ìœ„í•´ í°íŠ¸ ì‚¬ì´ì¦ˆ ì¡°ì • */
        line-height: 1.8;
    }
    
    .en-box { background-color: #f8f9fa; border: 2px solid #dee2e6; color: #212529; }
    .ko-box { background-color: #e3f2fd; border: 2px solid #90caf9; color: #0d47a1; }
    .label { font-weight: bold; margin-bottom: 10px; font-size: 16px; color: #555; }
    
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ë§ */
    div.stButton > button {
        width: 100%;
        height: 50px;
        font-size: 18px;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# 3. ëª¨ë¸ ë¡œë“œ
@st.cache_resource
def load_models():
    whisper = WhisperModel("tiny.en", device="cpu", compute_type="int8", cpu_threads=8)
    return whisper

try:
    with st.spinner("AI ëª¨ë¸ ë¡œë”© ì¤‘..."):
        model_whisper = load_models()
except Exception as e:
    st.error(f"ì˜¤ë¥˜: {e}")
    st.stop()

# 4. ìƒíƒœ ë³€ìˆ˜
if "is_listening" not in st.session_state: st.session_state.is_listening = False
if "audio_queue" not in st.session_state: st.session_state.audio_queue = queue.Queue()
if "stop_event" not in st.session_state: st.session_state.stop_event = threading.Event()
if "live_en" not in st.session_state: st.session_state.live_en = ""
if "live_ko" not in st.session_state: st.session_state.live_ko = ""
if "history" not in st.session_state: st.session_state.history = []

# --- ë…¹ìŒ ìŠ¤ë ˆë“œ ---
def record_thread(audio_queue, stop_event, energy_threshold):
    r = sr.Recognizer()
    r.energy_threshold = energy_threshold 
    r.dynamic_energy_threshold = False
    r.pause_threshold = 1.0

    try:
        with sr.Microphone() as source:
            accumulated_audio_data = io.BytesIO()
            speech_start_time = None
            has_speech = False
            MAX_SENTENCE_TIME = 10 

            while not stop_event.is_set():
                try:
                    audio_chunk = r.listen(source, timeout=1.0, phrase_time_limit=1.0)
                    accumulated_audio_data.write(audio_chunk.get_raw_data())

                    if not has_speech:
                        has_speech = True
                        speech_start_time = time.time()
                    
                    full_audio = sr.AudioData(accumulated_audio_data.getvalue(), source.SAMPLE_RATE, source.SAMPLE_WIDTH)
                    audio_queue.put((full_audio, False))

                    if time.time() - speech_start_time > MAX_SENTENCE_TIME:
                        audio_queue.put((full_audio, True))
                        accumulated_audio_data = io.BytesIO()
                        has_speech = False
                        speech_start_time = None
                
                except sr.WaitTimeoutError:
                    if has_speech:
                        full_audio = sr.AudioData(accumulated_audio_data.getvalue(), source.SAMPLE_RATE, source.SAMPLE_WIDTH)
                        audio_queue.put((full_audio, True))
                        accumulated_audio_data = io.BytesIO()
                        has_speech = False
                        speech_start_time = None
                    continue
                except:
                    break
    except:
        pass

# 5. UI êµ¬ì„±
sensitivity = st.slider("ğŸšï¸ ë§ˆì´í¬ ë¯¼ê°ë„", 100, 2000, 300, 50)

if st.session_state.is_listening:
    if st.button("â¹ï¸ í†µì—­ ì¤‘ì§€", type="primary"):
        st.session_state.is_listening = False
        st.session_state.stop_event.set()
        st.rerun()
else:
    if st.button("â–¶ï¸ í†µì—­ ì‹œì‘"):
        st.session_state.is_listening = True
        st.session_state.history = []
        st.session_state.live_en = ""
        st.session_state.live_ko = ""
        st.session_state.stop_event.clear()
        with st.session_state.audio_queue.mutex: st.session_state.audio_queue.queue.clear()
        
        t = threading.Thread(
            target=record_thread, 
            args=(st.session_state.audio_queue, st.session_state.stop_event, sensitivity), 
            daemon=True
        )
        t.start()
        st.rerun()

st.divider()

col1, col2 = st.columns(2)

# [UI ê°œì„ ] í…ìŠ¤íŠ¸ê°€ ì¤„ë°”ê¿ˆë˜ì–´ ë³´ì´ë„ë¡ div íƒœê·¸ë¡œ ê°ì‹¸ì„œ ê²°í•©
with col1:
    st.markdown("<div class='label'>ğŸ‡ºğŸ‡¸ ENGLISH</div>", unsafe_allow_html=True)
    
    # ì§€ë‚œ ëŒ€í™”ë“¤ì„ ê°ê°ì˜ divë¡œ ë¬¶ìŒ (ê°€ë…ì„± í–¥ìƒ)
    history_html = "".join([f"<div style='margin-bottom:8px;'>{h[0]}</div>" for h in st.session_state.history])
    
    # í˜„ì¬ ë§í•˜ê³  ìˆëŠ” ë¬¸ì¥ (ê°•ì¡°)
    if st.session_state.live_en:
        history_html += f"<div style='color:#d63384; font-weight:bold;'>{st.session_state.live_en} ...</div>"
    
    st.markdown(f"<div class='box en-box'>{history_html}</div>", unsafe_allow_html=True)

with col2:
    st.markdown("<div class='label'>ğŸ‡°ğŸ‡· KOREAN</div>", unsafe_allow_html=True)
    
    history_html_ko = "".join([f"<div style='margin-bottom:8px;'>{h[1]}</div>" for h in st.session_state.history])
    
    if st.session_state.live_ko:
        history_html_ko += f"<div style='color:#d63384; font-weight:bold;'>{st.session_state.live_ko} ...</div>"
        
    st.markdown(f"<div class='box ko-box'>{history_html_ko}</div>", unsafe_allow_html=True)

# 6. ë©”ì¸ ë¡œì§
if st.session_state.is_listening:
    if not st.session_state.audio_queue.empty():
        try:
            audio_data, is_final = st.session_state.audio_queue.get()
            
            temp_file = "temp_scroll.wav"
            with open(temp_file, "wb") as f: f.write(audio_data.get_wav_data())
            
            # Tiny ëª¨ë¸, Beam=2
            segments, _ = model_whisper.transcribe(temp_file, beam_size=2, temperature=0.0, language="en")
            text_en = "".join([s.text for s in segments]).strip()
            
            if text_en:
                try:
                    text_ko = argostranslate.translate.translate(text_en, "en", "ko")
                except:
                    text_ko = "..."

                st.session_state.live_en = text_en
                st.session_state.live_ko = text_ko
                
                if is_final:
                    st.session_state.history.append((text_en, text_ko))
                    st.session_state.live_en = ""
                    st.session_state.live_ko = ""
            
            st.rerun()

        except Exception as e:
            st.rerun()
    else:
        time.sleep(0.05)
        st.rerun()
