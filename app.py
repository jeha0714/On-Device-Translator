import streamlit as st
import speech_recognition as sr
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from faster_whisper import WhisperModel
import os
import time
import queue
import threading

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Stable Device Translator", page_icon="ğŸ¤", layout="wide")
st.title("ğŸ¤ Stable On-Device Translator")
st.caption("ìŠ¤ë ˆë“œ ì•ˆì „ì„±(Thread-Safe)ì´ ê°•í™”ëœ ë²„ì „ì…ë‹ˆë‹¤.")

# 2. ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .status-box { padding: 15px; border-radius: 8px; text-align: center; font-weight: bold; font-size: 20px; margin-bottom: 10px; }
    .listening { background-color: #E3F2FD; color: #1565C0; border: 2px solid #1565C0; }
    .translating { background-color: #E8F5E9; color: #2E7D32; border: 2px solid #2E7D32; }
</style>
""", unsafe_allow_html=True)

# 3. ëª¨ë¸ ë¡œë“œ
@st.cache_resource
def load_models():
    whisper = WhisperModel("base", device="cpu", compute_type="int8")
    llm = ChatOllama(model="gemma2:2b", temperature=0)
    return whisper, llm

try:
    with st.spinner("AI ëª¨ë¸ ë¡œë”© ì¤‘..."):
        model_whisper, llm = load_models()
    st.success("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
except Exception as e:
    st.error(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
    st.stop()

# ë²ˆì—­ ì²´ì¸
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a professional interpreter. Translate the English input into natural Korean. Output ONLY the Korean translation."),
    ("user", "{text}")
])
chain = prompt | llm | StrOutputParser()

# 4. ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
if "history" not in st.session_state: st.session_state.history = []
if "is_listening" not in st.session_state: st.session_state.is_listening = False
if "audio_queue" not in st.session_state: st.session_state.audio_queue = queue.Queue()
if "log_queue" not in st.session_state: st.session_state.log_queue = queue.Queue()
if "ui_status" not in st.session_state: st.session_state.ui_status = "Stopped"

# [í•µì‹¬ ë³€ê²½] ìŠ¤ë ˆë“œ ì œì–´ìš© ì´ë²¤íŠ¸ ê°ì²´ (session_state ëŒ€ì‹  ì‚¬ìš©)
if "stop_event" not in st.session_state:
    st.session_state.stop_event = threading.Event()

# --- ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ (session_state ì œê±°ë¨) ---
def record_thread(audio_queue, log_queue, energy_threshold, device_index, stop_event):
    r = sr.Recognizer()
    r.energy_threshold = energy_threshold
    r.dynamic_energy_threshold = False 
    r.pause_threshold = 1.5
    
    log_queue.put(f">>> [Thread] ë§ˆì´í¬(ID: {device_index}) ì—°ê²° ì‹œë„...")
    
    try:
        with sr.Microphone(device_index=device_index) as source:
            log_queue.put(">>> [Thread] ë§ˆì´í¬ ì—´ë¦¼! ë“£ê¸° ì‹œì‘...")
            
            # [ìˆ˜ì •] st.session_state ëŒ€ì‹  stop_event.is_set() ì²´í¬
            while not stop_event.is_set():
                try:
                    # 5ì´ˆ íƒ€ì„ì•„ì›ƒ
                    audio = r.listen(source, timeout=1, phrase_time_limit=15)
                    log_queue.put(">>> [Detected] ğŸ¤ ì˜¤ë””ì˜¤ ê°ì§€ë¨!")
                    audio_queue.put(audio)
                    
                except sr.WaitTimeoutError:
                    continue 
                except Exception as e:
                    log_queue.put(f">>> [Error] {e}")
                    break
            
            log_queue.put(">>> [Thread] ì¢…ë£Œ ì‹ í˜¸ í™•ì¸. ìŠ¤ë ˆë“œ ë©ˆì¶¤.")
            
    except Exception as e:
        log_queue.put(f">>> [Fatal Error] ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨: {e}")

# 5. ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ›ï¸ ì¥ì¹˜ ì„¤ì •")
    
    try:
        mics = sr.Microphone.list_microphone_names()
        mic_options = [f"{i}: {name}" for i, name in enumerate(mics)]
        
        default_idx = 0
        for i, name in enumerate(mics):
            if "Microphone" in name or "MacBook" in name:
                default_idx = i
                break
                
        selected_mic = st.selectbox("ë§ˆì´í¬ ì„ íƒ", mic_options, index=default_idx)
        selected_index = int(selected_mic.split(":")[0])
        
    except Exception as e:
        st.error("ë§ˆì´í¬ ëª©ë¡ ë¡œë”© ì‹¤íŒ¨")
        selected_index = None

    energy_threshold = st.slider("ë¯¼ê°ë„ (300 ê¶Œì¥)", 50, 1000, 300)
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("â–¶ï¸ ì‹œì‘", use_container_width=True):
            if not st.session_state.is_listening:
                st.session_state.is_listening = True
                st.session_state.ui_status = "Listening"
                
                # í ë° ì´ë²¤íŠ¸ ì´ˆê¸°í™”
                with st.session_state.audio_queue.mutex: st.session_state.audio_queue.queue.clear()
                with st.session_state.log_queue.mutex: st.session_state.log_queue.queue.clear()
                
                # ì •ì§€ ì‹ í˜¸ í•´ì œ (Falseë¡œ ì„¤ì •)
                st.session_state.stop_event.clear()
                
                # [ìˆ˜ì •] ìŠ¤ë ˆë“œì— stop_event ì „ë‹¬
                t = threading.Thread(
                    target=record_thread, 
                    args=(
                        st.session_state.audio_queue, 
                        st.session_state.log_queue, 
                        energy_threshold, 
                        selected_index, 
                        st.session_state.stop_event # ì—¬ê¸°!
                    ), 
                    daemon=True
                )
                t.start()
                st.rerun()
                
    with col2:
        if st.button("â¹ï¸ ì¤‘ì§€", use_container_width=True):
            st.session_state.is_listening = False
            st.session_state.ui_status = "Stopped"
            
            # ì •ì§€ ì‹ í˜¸ ë°œì†¡ (Trueë¡œ ì„¤ì •)
            st.session_state.stop_event.set()
            st.rerun()

    st.divider()
    st.caption("ğŸ“ ì‹¤ì‹œê°„ ë¡œê·¸")
    log_area = st.empty()

# 6. ë©”ì¸ í™”ë©´
status_placeholder = st.empty()

if st.session_state.ui_status == "Listening":
    status_placeholder.markdown('<div class="status-box listening">ğŸ”µ ë“£ê³  ìˆìŠµë‹ˆë‹¤... (ë§ì”€í•˜ì„¸ìš”)</div>', unsafe_allow_html=True)
elif st.session_state.ui_status == "Translating":
    status_placeholder.markdown('<div class="status-box translating">ğŸŸ¢ ê°ì§€ë¨! ë²ˆì—­ ì¤‘...</div>', unsafe_allow_html=True)
else:
    status_placeholder.markdown('<div class="status-box" style="background-color:#eee;">â¹ï¸ ëŒ€ê¸° ì¤‘</div>', unsafe_allow_html=True)

# 7. íˆìŠ¤í† ë¦¬
st.write("---")
for item in reversed(st.session_state.history):
    with st.container(border=True):
        st.markdown(f"**ğŸ‡ºğŸ‡¸ En:** {item['en']}")
        st.markdown(f"**ğŸ‡°ğŸ‡· Ko:** :blue[{item['ko']}]")

# 8. ë©”ì¸ ë£¨í”„
if st.session_state.is_listening:
    # ë¡œê·¸ ì—…ë°ì´íŠ¸
    logs = []
    while not st.session_state.log_queue.empty():
        logs.append(st.session_state.log_queue.get())
    
    if logs:
        with log_area.container():
            for log in reversed(logs[-10:]):
                st.text(log)

    # ì˜¤ë””ì˜¤ ì²˜ë¦¬
    if not st.session_state.audio_queue.empty():
        st.session_state.ui_status = "Translating"
        status_placeholder.markdown('<div class="status-box translating">ğŸŸ¢ ì²˜ë¦¬ ì¤‘...</div>', unsafe_allow_html=True)
        
        try:
            audio_data = st.session_state.audio_queue.get()
            temp_file = f"temp_{time.time()}.wav"
            with open(temp_file, "wb") as f: f.write(audio_data.get_wav_data())
            
            segments, _ = model_whisper.transcribe(temp_file, beam_size=5)
            text_en = "".join([s.text for s in segments]).strip()
            
            if text_en:
                translation = chain.invoke({"text": text_en})
                st.session_state.history.append({"en": text_en, "ko": translation})
            
            if os.path.exists(temp_file): os.remove(temp_file)
            
        except Exception as e:
            st.error(f"Error: {e}")
        
        st.session_state.ui_status = "Listening"
        st.rerun()
    else:
        time.sleep(0.5)
        st.rerun()
